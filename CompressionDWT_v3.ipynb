{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Data Compression Reconstruction by using Discrete Wavelet Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt # python library for wavelet transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load seismic and synthetic data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "# load data set: 50000 seismic signals\n",
    "filename_seismic = 'seismic_size50k_len256_znorm.bin'\n",
    "with open(filename_seismic, 'rb') as in_file:\n",
    "    time_series_seismic = np.array(struct.unpack('f' * 50000 * 256, in_file.read())).reshape(-1,256)\n",
    "\n",
    "# load data set: 50000 seismic signals\n",
    "filename_synthetic = 'synthetic_size50k_len256_znorm.bin'\n",
    "with open(filename_synthetic, 'rb') as in_file:\n",
    "    time_series_synthetic = np.array(struct.unpack('f' * 50000 * 256, in_file.read())).reshape(-1,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to compress and reconstruct time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression of data set 'x' to half size of 'x', e.g. 256 -> 128\n",
    "def compress(x):\n",
    "    compressed_x, cD = pywt.dwt(x, 'db1')\n",
    "    return compressed_x\n",
    "# reconstruction of data set 'y' to twice size of 'y', e.g. 128 -> 256\n",
    "def reconstruct(y):\n",
    "    reconstructed_y = pywt.idwt(y, None, 'db1')\n",
    "    return reconstructed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress 'x' i times and get a [x.size / 2**i] size data\n",
    "# e.g. using com_iterative(x, 3) on x which contains 256 float numbers,\n",
    "#      we'll have a compressed [256 / 2**3] = 32 float numbers\n",
    "def com_iterative(x, i):\n",
    "    for k in range(i):\n",
    "        compressed_x = compress(x)\n",
    "        x = compressed_x\n",
    "    return x\n",
    "# reconstruction of data set 'y' to [y.original_size * 2**i]\n",
    "def rec_iterative(y, i):\n",
    "    tmp = y\n",
    "    for k in range(i):\n",
    "        reconstructed_y = reconstruct(tmp)\n",
    "        tmp = reconstructed_y\n",
    "    return reconstructed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface functions to encode/decode easily\n",
    "def encoder128(x):\n",
    "    return com_iterative(x, int(math.log(x.shape[0]/128, 2)))\n",
    "def encoder64(x):\n",
    "    return com_iterative(x, int(math.log(x.shape[0]/64, 2)))\n",
    "def encoder32(x):\n",
    "    return com_iterative(x, int(math.log(x.shape[0]/32, 2)))\n",
    "def encoder16(x):\n",
    "    return com_iterative(x, int(math.log(x.shape[0]/16, 2)))\n",
    "def decoder256(y):\n",
    "    return rec_iterative(y, int(math.log(256/y.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data compression and reconstruction for seismic time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresized128_seismic = np.empty((0,128),float)\\nresized64_seismic = np.empty((0,64),float)\\nresized32_seismic = np.empty((0,32),float)\\nresized16_seismic = np.empty((0,16),float)\\n\\nreconstructed_128to256_seismic = np.empty((0,256),float)\\nreconstructed_64to256_seismic = np.empty((0,256),float)\\nreconstructed_32to256_seismic = np.empty((0,256),float)\\nreconstructed_16to256_seismic = np.empty((0,256),float)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables below is used to save time serie compression and reconstruction\n",
    "# For seismic data:\n",
    "'''\n",
    "resized128_seismic = np.empty((0,128),float)\n",
    "resized64_seismic = np.empty((0,64),float)\n",
    "resized32_seismic = np.empty((0,32),float)\n",
    "resized16_seismic = np.empty((0,16),float)\n",
    "\n",
    "reconstructed_128to256_seismic = np.empty((0,256),float)\n",
    "reconstructed_64to256_seismic = np.empty((0,256),float)\n",
    "reconstructed_32to256_seismic = np.empty((0,256),float)\n",
    "reconstructed_16to256_seismic = np.empty((0,256),float)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable to record reconstruction error\n",
    "error_128_seismic = 0.0\n",
    "error_64_seismic = 0.0\n",
    "error_32_seismic = 0.0\n",
    "error_16_seismic = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is to compress and reconstruct seismic data\n",
    "# every time serie will be compressed from 256 to 128/64/32/16 \n",
    "# then the compressed data will be \"enlarged\" from 128/64/32/16 to 256\n",
    "\n",
    "data_size = 50000\n",
    "for i in range(data_size):\n",
    "    \n",
    "    x = time_series_seismic[i,] # x contains 256 float numbers\n",
    "    \n",
    "    # 256 -> 128\n",
    "    resized_128 = encoder128(x)\n",
    "    reconstructed_128 = decoder256(resized_128)\n",
    "    error_128_seismic = error_128_seismic + float(np.linalg.norm(x - reconstructed_128))\n",
    "    \n",
    "    # 256 -> 64\n",
    "    resized_64 = encoder64(x)\n",
    "    reconstructed_64 = decoder256(resized_64)\n",
    "    error_64_seismic = error_64_seismic + float(np.linalg.norm(x - reconstructed_64))\n",
    "    \n",
    "    # 256 -> 32\n",
    "    resized_32 = encoder32(x)\n",
    "    reconstructed_32 = decoder256(resized_32)\n",
    "    error_32_seismic = error_32_seismic + float(np.linalg.norm(x - reconstructed_32))\n",
    "    \n",
    "    # 256 -> 16\n",
    "    resized_16 = encoder16(x)\n",
    "    reconstructed_16 = decoder256(resized_16)\n",
    "    error_16_seismic = error_16_seismic + float(np.linalg.norm(x - reconstructed_16))\n",
    "    \n",
    "    # Following code is to save compression and reconstruction to an array,\n",
    "    # saving data takes much time than you could imagine\n",
    "    # Please use the saved data in the folder \"compressed_50k\", \n",
    "    # an simple instruction to load data in the \"ReadMe\" file.\n",
    "    '''\n",
    "    resized128_seismic = np.vstack((resized128_seismic, resized_128))\n",
    "    reconstructed_128to256_seismic = np.vstack((reconstructed_128to256_seismic, reconstructed_128))\n",
    "    resized64_seismic = np.vstack((resized64_seismic, resized_64))\n",
    "    reconstructed_64to256_seismic = np.vstack((reconstructed_64to256_seismic, reconstructed_64))\n",
    "    resized32_seismic = np.vstack((resized32_seismic, resized_32))\n",
    "    reconstructed_32to256_seismic = np.vstack((reconstructed_32to256_seismic,reconstructed_32))\n",
    "    resized16_seismic = np.vstack((resized16_seismic, resized_16))\n",
    "    reconstructed_16to256_seismic = np.vstack((reconstructed_16to256_seismic,reconstructed_16))\n",
    "\n",
    "np.save(\"compressed128_50k_seismic.npy\", resized128_seismic)\n",
    "np.save(\"compressed64_50k_seismic.npy\", resized64_seismic)\n",
    "np.save(\"compressed32_50k_seismic.npy\", resized32_seismic)\n",
    "np.save(\"compressed16_50k_seismic.npy\", resized16_seismic)\n",
    "\n",
    "np.save(\"reconstructed_128to256_50k_seismic.npy\", reconstructed_128to256_seismic)\n",
    "np.save(\"reconstructed_64to256_50k_seismic.npy\", reconstructed_64to256_seismic)\n",
    "np.save(\"reconstructed_32to256_50k_seismic.npy\", reconstructed_32to256_seismic)\n",
    "np.save(\"reconstructed_16to256_50k_seismic.npy\", reconstructed_16to256_seismic)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall reconstruction error for  50000  time series: (128 / 64 / 32 / 16)\n",
      "632932.170386034 771074.4015698319 790471.3970702328 797346.2607445099\n",
      "Average reconstruction error for  50000  time series: (128 / 64 / 32 / 16)\n",
      "12.658643407720678 15.421488031396638 15.809427941404655 15.946925214890197\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall reconstruction error for \", data_size, \" time series: (128 / 64 / 32 / 16)\")\n",
    "print(error_128_seismic, error_64_seismic, error_32_seismic, error_16_seismic)\n",
    "print(\"Average reconstruction error for \", data_size, \" time series: (128 / 64 / 32 / 16)\")\n",
    "print(error_128_seismic/data_size, error_64_seismic/data_size, error_32_seismic/data_size, error_16_seismic/data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data compression and reconstruction for synthetic time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresized128_synthetic = np.empty((0,128),float)\\nresized64_synthetic = np.empty((0,64),float)\\nresized32_synthetic = np.empty((0,32),float)\\nresized16_synthetic = np.empty((0,16),float)\\n\\nreconstructed_128to256_synthetic = np.empty((0,256),float)\\nreconstructed_64to256_synthetic = np.empty((0,256),float)\\nreconstructed_32to256_synthetic = np.empty((0,256),float)\\nreconstructed_16to256_synthetic = np.empty((0,256),float)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables below is used to save time serie compression and reconstruction\n",
    "# For synthetic data:\n",
    "'''\n",
    "resized128_synthetic = np.empty((0,128),float)\n",
    "resized64_synthetic = np.empty((0,64),float)\n",
    "resized32_synthetic = np.empty((0,32),float)\n",
    "resized16_synthetic = np.empty((0,16),float)\n",
    "\n",
    "reconstructed_128to256_synthetic = np.empty((0,256),float)\n",
    "reconstructed_64to256_synthetic = np.empty((0,256),float)\n",
    "reconstructed_32to256_synthetic = np.empty((0,256),float)\n",
    "reconstructed_16to256_synthetic = np.empty((0,256),float)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable to record reconstruction error\n",
    "error_128_synthetic = 0.0\n",
    "error_64_synthetic = 0.0\n",
    "error_32_synthetic = 0.0\n",
    "error_16_synthetic = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is to compress and reconstruct seismic data\n",
    "# every time serie will be compressed from 256 to 128/64/32/16 \n",
    "# then the compressed data will be \"enlarged\" from 128/64/32/16 to 256\n",
    "\n",
    "data_size = 50000\n",
    "for i in range(data_size):\n",
    "    \n",
    "    x = time_series_synthetic[i,] # x contains 256 float numbers\n",
    "    \n",
    "    # 256 -> 128\n",
    "    resized_128 = encoder128(x)\n",
    "    reconstructed_128 = decoder256(resized_128)\n",
    "    error_128_synthetic = error_128_synthetic + float(np.linalg.norm(x - reconstructed_128))\n",
    "    \n",
    "    # 256 -> 64\n",
    "    resized_64 = encoder64(x)\n",
    "    reconstructed_64 = decoder256(resized_64)\n",
    "    error_64_synthetic = error_64_synthetic + float(np.linalg.norm(x - reconstructed_64))\n",
    "    \n",
    "    # 256 -> 32\n",
    "    resized_32 = encoder32(x)\n",
    "    reconstructed_32 = decoder256(resized_32)\n",
    "    error_32_synthetic = error_32_synthetic + float(np.linalg.norm(x - reconstructed_32))\n",
    "    \n",
    "    # 256 -> 16\n",
    "    resized_16 = encoder16(x)\n",
    "    reconstructed_16 = decoder256(resized_16)\n",
    "    error_16_synthetic = error_16_synthetic + float(np.linalg.norm(x - reconstructed_16))\n",
    "    \n",
    "    # Following code is to save compression and reconstruction to an array,\n",
    "    # saving data takes much time than you could imagine\n",
    "    # Please use the saved data in the folder \"compressed_50k\", \n",
    "    # an simple instruction to load data in the \"ReadMe\" file.\n",
    "    '''\n",
    "    resized128_synthetic = np.vstack((resized128_synthetic, resized_128))\n",
    "    reconstructed_128to256_synthetic = np.vstack((reconstructed_128to256_synthetic, reconstructed_128))\n",
    "    resized64_synthetic = np.vstack((resized64_synthetic, resized_64))\n",
    "    reconstructed_64to256_synthetic = np.vstack((reconstructed_64to256_synthetic, reconstructed_64))\n",
    "    resized32_synthetic = np.vstack((resized32_synthetic, resized_32))\n",
    "    reconstructed_32to256_synthetic = np.vstack((reconstructed_32to256_synthetic,reconstructed_32))\n",
    "    resized16_synthetic = np.vstack((resized16_synthetic, resized_16))\n",
    "    reconstructed_16to256_synthetic = np.vstack((reconstructed_16to256_synthetic,reconstructed_16))\n",
    "\n",
    "np.save(\"compressed128_50k_synthetic.npy\", resized128_synthetic)\n",
    "np.save(\"compressed64_50k_synthetic.npy\", resized64_synthetic)\n",
    "np.save(\"compressed32_50k_synthetic.npy\", resized32_synthetic)\n",
    "np.save(\"compressed16_50k_synthetic.npy\", resized16_synthetic)\n",
    "\n",
    "np.save(\"reconstructed_128to256_50k_synthetic.npy\", reconstructed_128to256_synthetic)\n",
    "np.save(\"reconstructed_64to256_50k_synthetic.npy\", reconstructed_64to256_synthetic)\n",
    "np.save(\"reconstructed_32to256_50k_synthetic.npy\", reconstructed_32to256_synthetic)\n",
    "np.save(\"reconstructed_16to256_50k_synthetic.npy\", reconstructed_16to256_synthetic)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall reconstruction error for  50000  time series: (128 / 64 / 32 / 16)\n",
      "76273.23288734269 120327.73912184678 173555.64466821024 244335.4583699993\n",
      "Average reconstruction error for  50000  time series: (128 / 64 / 32 / 16)\n",
      "1.5254646577468538 2.4065547824369355 3.4711128933642046 4.886709167399986\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall reconstruction error for \", data_size, \" time series: (128 / 64 / 32 / 16)\")\n",
    "print(error_128_synthetic, error_64_synthetic, error_32_synthetic, error_16_synthetic)\n",
    "print(\"Average reconstruction error for \", data_size, \" time series: (128 / 64 / 32 / 16)\")\n",
    "print(error_128_synthetic/data_size, error_64_synthetic/data_size, error_32_synthetic/data_size, error_16_synthetic/data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search\n",
    "# to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
